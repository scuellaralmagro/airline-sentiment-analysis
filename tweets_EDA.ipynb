{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# US Airline Sentiment Analysis - Exploratory Data Analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will be conducting an Exploratory Data Analysis on a dataset containing tweets about various US airlines. This data was scraped from Febraury 2015 and contributors were asked to first classify positive, negative, and neutral tweets, followed by categorizing negative reasons (such as \"late flight\" or \"rude service\").\n",
    "\n",
    "- **Author:** [Sergio Cu√©llar](https://www.linkedin.com/in/sergiocuellaralmagro/)\n",
    "- **Date:** February 2023\n",
    "- **Dataset:** [Kaggle](https://www.kaggle.com/crowdflower/twitter-airline-sentiment)\n",
    "- **Python Version:** 3.10.10"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the main objectives of this exploratory data analysis:\n",
    "- To gain an understanding of the characteristics of the dataset containing tweets about various US airlines.\n",
    "- To explore the distribution of sentiment labels (positive, negative, and neutral) assigned to the tweets and identify any patterns or trends in the data.\n",
    "- To analyze the negative reasons (such as \"late flight\" or \"rude service\") given by contributors and understand the most common reasons for negative sentiment.\n",
    "- To identify any outliers, missing data or inconsistencies in the dataset that may need to be addressed before further analysis.\n",
    "- To use various statistical and visualization techniques to summarize and present the findings from the analysis.\n",
    "\n",
    "Overall, the goal of the EDA is to gain insights into the data and use those insights to inform further analysis, modeling and decision making.\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library Imports and Setup"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using the following libraries for this analysis:\n",
    "\n",
    "- **pandas:** For data manipulation and analysis.\n",
    "- **numpy:** For numerical computing.\n",
    "- **matplotlib:** For data visualization.\n",
    "- **seaborn:** Runs on top of matplotlib and provides a high-level interface for drawing attractive and informative statistical graphics.\n",
    "- **wordcloud:** For generating word clouds.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import wordcloud"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also be using the following settings to display the plots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('darkgrid',{\n",
    "    'axes.facecolor': '0.9',\n",
    "    'grid.color': '0.8',\n",
    "    'grid.linestyle': '--',\n",
    "    'grid.linewidth': 0.5,\n",
    "    })"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Loading and Preliminary Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_sentiment_gold</th>\n",
       "      <th>name</th>\n",
       "      <th>negativereason_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>570306133677760513</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cairdin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:35:52 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>570301130888122368</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:59 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>570301083672813571</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yvonnalynn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:48 -0800</td>\n",
       "      <td>Lets Play</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>570301031407624196</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Bad Flight</td>\n",
       "      <td>0.7033</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:36 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>570300817074462722</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Can't Tell</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:14:45 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>570300767074181121</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Can't Tell</td>\n",
       "      <td>0.6842</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica seriously would pay $30 a fligh...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:14:33 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>570300616901320704</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.6745</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cjmcginnis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica yes, nearly every time I fly VX...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:13:57 -0800</td>\n",
       "      <td>San Francisco CA</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>570300248553349120</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6340</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pilot</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica Really missed a prime opportuni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:12:29 -0800</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>570299953286942721</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.6559</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dhepburn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@virginamerica Well, I didn't‚Ä¶but NOW I DO! :-D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:11:19 -0800</td>\n",
       "      <td>San Diego</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>570295459631263746</td>\n",
       "      <td>positive</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>YupitsTate</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica it was amazing, and arrived an ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 10:53:27 -0800</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id airline_sentiment  airline_sentiment_confidence  \\\n",
       "0  570306133677760513           neutral                        1.0000   \n",
       "1  570301130888122368          positive                        0.3486   \n",
       "2  570301083672813571           neutral                        0.6837   \n",
       "3  570301031407624196          negative                        1.0000   \n",
       "4  570300817074462722          negative                        1.0000   \n",
       "5  570300767074181121          negative                        1.0000   \n",
       "6  570300616901320704          positive                        0.6745   \n",
       "7  570300248553349120           neutral                        0.6340   \n",
       "8  570299953286942721          positive                        0.6559   \n",
       "9  570295459631263746          positive                        1.0000   \n",
       "\n",
       "  negativereason  negativereason_confidence         airline  \\\n",
       "0            NaN                        NaN  Virgin America   \n",
       "1            NaN                     0.0000  Virgin America   \n",
       "2            NaN                        NaN  Virgin America   \n",
       "3     Bad Flight                     0.7033  Virgin America   \n",
       "4     Can't Tell                     1.0000  Virgin America   \n",
       "5     Can't Tell                     0.6842  Virgin America   \n",
       "6            NaN                     0.0000  Virgin America   \n",
       "7            NaN                        NaN  Virgin America   \n",
       "8            NaN                        NaN  Virgin America   \n",
       "9            NaN                        NaN  Virgin America   \n",
       "\n",
       "  airline_sentiment_gold        name negativereason_gold  retweet_count  \\\n",
       "0                    NaN     cairdin                 NaN              0   \n",
       "1                    NaN    jnardino                 NaN              0   \n",
       "2                    NaN  yvonnalynn                 NaN              0   \n",
       "3                    NaN    jnardino                 NaN              0   \n",
       "4                    NaN    jnardino                 NaN              0   \n",
       "5                    NaN    jnardino                 NaN              0   \n",
       "6                    NaN  cjmcginnis                 NaN              0   \n",
       "7                    NaN       pilot                 NaN              0   \n",
       "8                    NaN    dhepburn                 NaN              0   \n",
       "9                    NaN  YupitsTate                 NaN              0   \n",
       "\n",
       "                                                text tweet_coord  \\\n",
       "0                @VirginAmerica What @dhepburn said.         NaN   \n",
       "1  @VirginAmerica plus you've added commercials t...         NaN   \n",
       "2  @VirginAmerica I didn't today... Must mean I n...         NaN   \n",
       "3  @VirginAmerica it's really aggressive to blast...         NaN   \n",
       "4  @VirginAmerica and it's a really big bad thing...         NaN   \n",
       "5  @VirginAmerica seriously would pay $30 a fligh...         NaN   \n",
       "6  @VirginAmerica yes, nearly every time I fly VX...         NaN   \n",
       "7  @VirginAmerica Really missed a prime opportuni...         NaN   \n",
       "8    @virginamerica Well, I didn't‚Ä¶but NOW I DO! :-D         NaN   \n",
       "9  @VirginAmerica it was amazing, and arrived an ...         NaN   \n",
       "\n",
       "               tweet_created    tweet_location               user_timezone  \n",
       "0  2015-02-24 11:35:52 -0800               NaN  Eastern Time (US & Canada)  \n",
       "1  2015-02-24 11:15:59 -0800               NaN  Pacific Time (US & Canada)  \n",
       "2  2015-02-24 11:15:48 -0800         Lets Play  Central Time (US & Canada)  \n",
       "3  2015-02-24 11:15:36 -0800               NaN  Pacific Time (US & Canada)  \n",
       "4  2015-02-24 11:14:45 -0800               NaN  Pacific Time (US & Canada)  \n",
       "5  2015-02-24 11:14:33 -0800               NaN  Pacific Time (US & Canada)  \n",
       "6  2015-02-24 11:13:57 -0800  San Francisco CA  Pacific Time (US & Canada)  \n",
       "7  2015-02-24 11:12:29 -0800       Los Angeles  Pacific Time (US & Canada)  \n",
       "8  2015-02-24 11:11:19 -0800         San Diego  Pacific Time (US & Canada)  \n",
       "9  2015-02-24 10:53:27 -0800       Los Angeles  Eastern Time (US & Canada)  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/Tweets.csv')\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset has 14640 rows and 15 columns.\n"
     ]
    }
   ],
   "source": [
    "shape = data.shape\n",
    "print(f'The dataset has {shape[0]} rows and {shape[1]} columns.') # Print the shape of the dataset in a readable format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The columns are:\n",
      "\t tweet_id\n",
      "\t airline_sentiment\n",
      "\t airline_sentiment_confidence\n",
      "\t negativereason\n",
      "\t negativereason_confidence\n",
      "\t airline\n",
      "\t airline_sentiment_gold\n",
      "\t name\n",
      "\t negativereason_gold\n",
      "\t retweet_count\n",
      "\t text\n",
      "\t tweet_coord\n",
      "\t tweet_created\n",
      "\t tweet_location\n",
      "\t user_timezone\n"
     ]
    }
   ],
   "source": [
    "columns = data.columns\n",
    "\n",
    "# Print the columns of the dataset in a readable format.\n",
    "print('The columns are:')\n",
    "for column in columns:\n",
    "    print('\\t',column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14640 entries, 0 to 14639\n",
      "Data columns (total 15 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   tweet_id                      14640 non-null  int64  \n",
      " 1   airline_sentiment             14640 non-null  object \n",
      " 2   airline_sentiment_confidence  14640 non-null  float64\n",
      " 3   negativereason                9178 non-null   object \n",
      " 4   negativereason_confidence     10522 non-null  float64\n",
      " 5   airline                       14640 non-null  object \n",
      " 6   airline_sentiment_gold        40 non-null     object \n",
      " 7   name                          14640 non-null  object \n",
      " 8   negativereason_gold           32 non-null     object \n",
      " 9   retweet_count                 14640 non-null  int64  \n",
      " 10  text                          14640 non-null  object \n",
      " 11  tweet_coord                   1019 non-null   object \n",
      " 12  tweet_created                 14640 non-null  object \n",
      " 13  tweet_location                9907 non-null   object \n",
      " 14  user_timezone                 9820 non-null   object \n",
      "dtypes: float64(2), int64(2), object(11)\n",
      "memory usage: 1.7+ MB\n"
     ]
    }
   ],
   "source": [
    "# Print a summary of the dataset.\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>retweet_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.464000e+04</td>\n",
       "      <td>14640.000000</td>\n",
       "      <td>10522.000000</td>\n",
       "      <td>14640.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.692184e+17</td>\n",
       "      <td>0.900169</td>\n",
       "      <td>0.638298</td>\n",
       "      <td>0.082650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.791112e+14</td>\n",
       "      <td>0.162830</td>\n",
       "      <td>0.330440</td>\n",
       "      <td>0.745778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>5.675883e+17</td>\n",
       "      <td>0.335000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.685592e+17</td>\n",
       "      <td>0.692300</td>\n",
       "      <td>0.360600</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.694779e+17</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.670600</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.698905e+17</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.703106e+17</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>44.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           tweet_id  airline_sentiment_confidence  negativereason_confidence  \\\n",
       "count  1.464000e+04                  14640.000000               10522.000000   \n",
       "mean   5.692184e+17                      0.900169                   0.638298   \n",
       "std    7.791112e+14                      0.162830                   0.330440   \n",
       "min    5.675883e+17                      0.335000                   0.000000   \n",
       "25%    5.685592e+17                      0.692300                   0.360600   \n",
       "50%    5.694779e+17                      1.000000                   0.670600   \n",
       "75%    5.698905e+17                      1.000000                   1.000000   \n",
       "max    5.703106e+17                      1.000000                   1.000000   \n",
       "\n",
       "       retweet_count  \n",
       "count   14640.000000  \n",
       "mean        0.082650  \n",
       "std         0.745778  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max        44.000000  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a summary of the numerical columns.\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_sentiment_gold</th>\n",
       "      <th>name</th>\n",
       "      <th>negativereason_gold</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>14640</td>\n",
       "      <td>9178</td>\n",
       "      <td>14640</td>\n",
       "      <td>40</td>\n",
       "      <td>14640</td>\n",
       "      <td>32</td>\n",
       "      <td>14640</td>\n",
       "      <td>1019</td>\n",
       "      <td>14640</td>\n",
       "      <td>9907</td>\n",
       "      <td>9820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>7701</td>\n",
       "      <td>13</td>\n",
       "      <td>14427</td>\n",
       "      <td>832</td>\n",
       "      <td>14247</td>\n",
       "      <td>3081</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>negative</td>\n",
       "      <td>Customer Service Issue</td>\n",
       "      <td>United</td>\n",
       "      <td>negative</td>\n",
       "      <td>JetBlueNews</td>\n",
       "      <td>Customer Service Issue</td>\n",
       "      <td>@united thanks</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>2015-02-24 09:54:34 -0800</td>\n",
       "      <td>Boston, MA</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>9178</td>\n",
       "      <td>2910</td>\n",
       "      <td>3822</td>\n",
       "      <td>32</td>\n",
       "      <td>63</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>164</td>\n",
       "      <td>5</td>\n",
       "      <td>157</td>\n",
       "      <td>3744</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       airline_sentiment          negativereason airline  \\\n",
       "count              14640                    9178   14640   \n",
       "unique                 3                      10       6   \n",
       "top             negative  Customer Service Issue  United   \n",
       "freq                9178                    2910    3822   \n",
       "\n",
       "       airline_sentiment_gold         name     negativereason_gold  \\\n",
       "count                      40        14640                      32   \n",
       "unique                      3         7701                      13   \n",
       "top                  negative  JetBlueNews  Customer Service Issue   \n",
       "freq                       32           63                      12   \n",
       "\n",
       "                  text tweet_coord              tweet_created tweet_location  \\\n",
       "count            14640        1019                      14640           9907   \n",
       "unique           14427         832                      14247           3081   \n",
       "top     @united thanks  [0.0, 0.0]  2015-02-24 09:54:34 -0800     Boston, MA   \n",
       "freq                 6         164                          5            157   \n",
       "\n",
       "                     user_timezone  \n",
       "count                         9820  \n",
       "unique                          85  \n",
       "top     Eastern Time (US & Canada)  \n",
       "freq                          3744  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a summary of the categorical columns.\n",
    "data.describe(include=['O'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet_id                         0.000000\n",
       "airline_sentiment                0.000000\n",
       "airline_sentiment_confidence     0.000000\n",
       "negativereason                  37.308743\n",
       "negativereason_confidence       28.128415\n",
       "airline                          0.000000\n",
       "airline_sentiment_gold          99.726776\n",
       "name                             0.000000\n",
       "negativereason_gold             99.781421\n",
       "retweet_count                    0.000000\n",
       "text                             0.000000\n",
       "tweet_coord                     93.039617\n",
       "tweet_created                    0.000000\n",
       "tweet_location                  32.329235\n",
       "user_timezone                   32.923497\n",
       "dtype: float64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the percentage of missing values in each column.\n",
    "data.isnull().sum()/data.shape[0]*100"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can conclude from this preliminary inspection, the dataset contains 14.640 tweets about US airlines. There are 4 numerical columns (tweet_id, airline_sentiment_confidence, negativereason_confidence, and retweet_count) and 11 categorical columns (airline, airline_sentiment, name, negativereason, retweet_count, text, tweet_coord, tweet_created, tweet_location, user_timezone, and user_timezone).\n",
    "\n",
    "Some of the columns contain a very high percentage of missing values (airline_sentiment_gold, negativereason_gold and tweet_coord). We will need to decide whether to drop these columns or impute the missing values. We will discuss this further in the data cleaning section."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will be cleaning the data and addressing any missing values, outliers, or inconsistencies in the dataset."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting tweet_created to datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14640 entries, 0 to 14639\n",
      "Data columns (total 15 columns):\n",
      " #   Column                        Non-Null Count  Dtype                                 \n",
      "---  ------                        --------------  -----                                 \n",
      " 0   tweet_id                      14640 non-null  int64                                 \n",
      " 1   airline_sentiment             14640 non-null  object                                \n",
      " 2   airline_sentiment_confidence  14640 non-null  float64                               \n",
      " 3   negativereason                9178 non-null   object                                \n",
      " 4   negativereason_confidence     10522 non-null  float64                               \n",
      " 5   airline                       14640 non-null  object                                \n",
      " 6   airline_sentiment_gold        40 non-null     object                                \n",
      " 7   name                          14640 non-null  object                                \n",
      " 8   negativereason_gold           32 non-null     object                                \n",
      " 9   retweet_count                 14640 non-null  int64                                 \n",
      " 10  text                          14640 non-null  object                                \n",
      " 11  tweet_coord                   1019 non-null   object                                \n",
      " 12  tweet_created                 14640 non-null  datetime64[ns, pytz.FixedOffset(-480)]\n",
      " 13  tweet_location                9907 non-null   object                                \n",
      " 14  user_timezone                 9820 non-null   object                                \n",
      "dtypes: datetime64[ns, pytz.FixedOffset(-480)](1), float64(2), int64(2), object(10)\n",
      "memory usage: 1.7+ MB\n"
     ]
    }
   ],
   "source": [
    "# Convert the date column to datetime format.\n",
    "data['tweet_created'] = pd.to_datetime(data['tweet_created'])\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset contains tweets from 2015-02-16 23:36:05-08:00 to 2015-02-24 11:53:37-08:00.\n"
     ]
    }
   ],
   "source": [
    "date_min = data['tweet_created'].min()\n",
    "date_max = data['tweet_created'].max()\n",
    "\n",
    "print(f'The dataset contains tweets from {date_min} to {date_max}.') # Print the date range of the dataset."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with columns containing missing values"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we concluded earlier, there are 3 columns with a percentage of over 90% of missing values: airline_sentiment_gold, negativereason_gold and tweet_coord. We will drop these columns from the dataset, as they will not be providing any useful information for our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14640 entries, 0 to 14639\n",
      "Data columns (total 12 columns):\n",
      " #   Column                        Non-Null Count  Dtype                                 \n",
      "---  ------                        --------------  -----                                 \n",
      " 0   tweet_id                      14640 non-null  int64                                 \n",
      " 1   airline_sentiment             14640 non-null  object                                \n",
      " 2   airline_sentiment_confidence  14640 non-null  float64                               \n",
      " 3   negativereason                9178 non-null   object                                \n",
      " 4   negativereason_confidence     10522 non-null  float64                               \n",
      " 5   airline                       14640 non-null  object                                \n",
      " 6   name                          14640 non-null  object                                \n",
      " 7   retweet_count                 14640 non-null  int64                                 \n",
      " 8   text                          14640 non-null  object                                \n",
      " 9   tweet_created                 14640 non-null  datetime64[ns, pytz.FixedOffset(-480)]\n",
      " 10  tweet_location                9907 non-null   object                                \n",
      " 11  user_timezone                 9820 non-null   object                                \n",
      "dtypes: datetime64[ns, pytz.FixedOffset(-480)](1), float64(2), int64(2), object(7)\n",
      "memory usage: 1.3+ MB\n"
     ]
    }
   ],
   "source": [
    "def columns_drop(df, columns):\n",
    "    '''Drops columns from a dataframe'''\n",
    "    return df.drop(columns, axis=1)\n",
    "\n",
    "# Drop columns with more than 90% missing values.\n",
    "data = columns_drop(data, ['airline_sentiment_gold', 'negativereason_gold', 'tweet_coord'])\n",
    "data.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now take a look at the remaining columns with missing values. We will be checking column by column to see if we can impute the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet_id                         0.000000\n",
       "airline_sentiment                0.000000\n",
       "airline_sentiment_confidence     0.000000\n",
       "negativereason                  37.308743\n",
       "negativereason_confidence       28.128415\n",
       "airline                          0.000000\n",
       "name                             0.000000\n",
       "retweet_count                    0.000000\n",
       "text                             0.000000\n",
       "tweet_created                    0.000000\n",
       "tweet_location                  32.329235\n",
       "user_timezone                   32.923497\n",
       "dtype: float64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the percentage of missing values in each column.\n",
    "data.isnull().sum()/data.shape[0]*100"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 'negativereason' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, 'Bad Flight', \"Can't Tell\", 'Late Flight',\n",
       "       'Customer Service Issue', 'Flight Booking Problems',\n",
       "       'Lost Luggage', 'Flight Attendant Complaints', 'Cancelled Flight',\n",
       "       'Damaged Luggage', 'longlines'], dtype=object)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.negativereason.unique() # Print the unique values in the negativereason column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "negativereason\n",
       "Customer Service Issue         2910\n",
       "Late Flight                    1665\n",
       "Can't Tell                     1190\n",
       "Cancelled Flight                847\n",
       "Lost Luggage                    724\n",
       "Bad Flight                      580\n",
       "Flight Booking Problems         529\n",
       "Flight Attendant Complaints     481\n",
       "longlines                       178\n",
       "Damaged Luggage                  74\n",
       "dtype: int64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby('negativereason').size().sort_values(ascending=False) # Print the number of tweets for each negative reason."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be replacing the missing values in the 'negativereason' column with the string 'Can't Tell', as they are tweets that were classified as negative but no reason was given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "negativereason\n",
       "Can't Tell                     6652\n",
       "Customer Service Issue         2910\n",
       "Late Flight                    1665\n",
       "Cancelled Flight                847\n",
       "Lost Luggage                    724\n",
       "Bad Flight                      580\n",
       "Flight Booking Problems         529\n",
       "Flight Attendant Complaints     481\n",
       "longlines                       178\n",
       "Damaged Luggage                  74\n",
       "dtype: int64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace the missing values in the negativereason column with 'Can't Tell'.\n",
    "data['negativereason'].fillna(\"Can't Tell\", inplace=True)\n",
    "data.groupby('negativereason').size().sort_values(ascending=False) # Print the number of tweets for each negative reason after imputation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if there are any missing values in the negativereason column.\n",
    "data['negativereason'].isnull().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 'negativereason_confidence' column"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this is a numerical column, we will be replacing the missing values with the mean of the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean of the negativereason_confidence column.\n",
    "negativereason_confidence_mean = data['negativereason_confidence'].mean()\n",
    "\n",
    "# Replace the missing values in the negativereason_confidence column with the mean.\n",
    "data['negativereason_confidence'].fillna(negativereason_confidence_mean, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if there are any missing values in the negativereason_confidence column.\n",
    "data['negativereason_confidence'].isnull().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 'tweet_location' column"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This column contains the location of the tweet. Around 32% of the values are missing, so we will be replacing the missing values with the string 'Unknown'. We will also be merging the locations that are very similar, such as 'New York' and 'New York City'. We will only be doing this for the top 25 locations, as there are many different locations in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3081 unique values in the tweet_location column.\n"
     ]
    }
   ],
   "source": [
    "# Print the number of unique values in the tweet_location column.\n",
    "print(f'There are {data.tweet_location.nunique()} unique values in the tweet_location column.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet_location\n",
       "Boston, MA           157\n",
       "New York, NY         156\n",
       "Washington, DC       150\n",
       "New York             127\n",
       "USA                  126\n",
       "Chicago              104\n",
       "New York City         96\n",
       "Los Angeles, CA       96\n",
       "NYC                   95\n",
       "San Francisco, CA     91\n",
       "San Francisco         86\n",
       "Chicago, IL           81\n",
       "Brooklyn, NY          66\n",
       "Los Angeles           64\n",
       "Austin, TX            64\n",
       "Washington, D.C.      63\n",
       "Boston                62\n",
       "Dallas, TX            54\n",
       "Washington DC         53\n",
       "Nashville, TN         45\n",
       "dtype: int64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby('tweet_location').size().sort_values(ascending=False).head(20) # Print the top 25 locations with the most tweets."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be merging the locations tags that point to the same location. These are the locations that we will be merging:\n",
    "- 'New York', 'New York, NY', 'New York City' will be merged into 'New York, NY'.\n",
    "- 'Boston, MA' and 'Boston' will be merged into 'Boston, MA'.\n",
    "- 'Washington, DC' and 'Washington, D.C.' will be merged into 'Washington, DC'.\n",
    "- 'Los Angeles, CA' and 'Los Angeles' will be merged into 'Los Angeles, CA'.\n",
    "- 'San Francisco, CA' and 'San Francisco' will be merged into 'San Francisco, CA'.\n",
    "- 'Chicago, IL' and 'Chicago' will be merged into 'Chicago, IL'.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge all the locations that refer to New York into 'New York, NY'.\n",
    "data['tweet_location'] = data['tweet_location'].replace(['New York', 'New York City', 'NY', 'NYC', 'New York, New York'], 'New York, NY')\n",
    "\n",
    "# Merge 'Boston, MA' and 'Boston' into 'Boston, MA'.\n",
    "data['tweet_location'] = data['tweet_location'].replace('Boston', 'Boston, MA')\n",
    "\n",
    "# Merge 'Washington, DC' and 'Washington, D.C.' into 'Washington, DC'.\n",
    "data['tweet_location'] = data['tweet_location'].replace(['Washington, D.C.', 'DC', 'Washington DC'], 'Washington, DC')\n",
    "\n",
    "# Merge 'Los Angeles, CA' and 'Los Angeles' into 'Los Angeles, CA'.\n",
    "data['tweet_location'] = data['tweet_location'].replace('Los Angeles', 'Los Angeles, CA')\n",
    "\n",
    "# Merge 'San Francisco, CA' and 'San Francisco' into 'San Francisco, CA'.\n",
    "data['tweet_location'] = data['tweet_location'].replace('San Francisco', 'San Francisco, CA')\n",
    "\n",
    "# Merge 'Chicago, IL' and 'Chicago' into 'Chicago, IL'.\n",
    "data['tweet_location'] = data['tweet_location'].replace('Chicago', 'Chicago, IL')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet_location\n",
       "New York, NY                   547\n",
       "Washington, DC                 294\n",
       "Boston, MA                     219\n",
       "Chicago, IL                    185\n",
       "San Francisco, CA              177\n",
       "Los Angeles, CA                160\n",
       "USA                            126\n",
       "Brooklyn, NY                    66\n",
       "Austin, TX                      64\n",
       "Dallas, TX                      54\n",
       "Nashville, TN                   45\n",
       "Texas                           42\n",
       "Philadelphia, PA                38\n",
       "San Diego                       38\n",
       "Denver, CO                      37\n",
       "Houston, TX                     35\n",
       "Seattle                         34\n",
       "Global                          34\n",
       "Logan International Airport     32\n",
       "London                          30\n",
       "Las Vegas, NV                   30\n",
       "New Jersey                      29\n",
       "Raleigh, NC                     28\n",
       "Pekin                           28\n",
       "Arlington, VA                   27\n",
       "dtype: int64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the top 25 locations with the most tweets after merging.\n",
    "data.groupby('tweet_location').size().sort_values(ascending=False).head(25)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now be replacing the remaining missing values in the 'tweet_location' column with the string 'Unknown'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4733"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the number of missing values in the tweet_location column.\n",
    "data['tweet_location'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the missing values in the tweet_location column with 'Unknown'.\n",
    "data['tweet_location'].fillna('Unknown', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if there are any missing values in the tweet_location column.\n",
    "data['tweet_location'].isnull().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 'user_timezone' column"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be replacing the missing values in the 'user_timezone' column with the string 'Unknown'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4820"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the number of missing values in the user_timezone column.\n",
    "data['user_timezone'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the missing values in the user_timezone column with 'Unknown'.\n",
    "data['user_timezone'].fillna('Unknown', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if there are any missing values in the user_timezone column.\n",
    "data['user_timezone'].isnull().sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2189e5d8aae29d61ba9f9616771ebb0092daedb34f0d968b396f951e3791d2bf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
